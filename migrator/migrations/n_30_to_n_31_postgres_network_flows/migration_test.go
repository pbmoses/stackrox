// Code generated by pg-bindings generator. DO NOT EDIT.

package n30ton31

import (
	"context"
	"sort"
	"testing"

	"github.com/gogo/protobuf/types"
	"github.com/jackc/pgx/v4/pgxpool"
	"github.com/stackrox/rox/generated/storage"
	legacy "github.com/stackrox/rox/migrator/migrations/n_30_to_n_31_postgres_network_flows/legacy"
	"github.com/stackrox/rox/migrator/migrations/n_30_to_n_31_postgres_network_flows/store"
	"github.com/stackrox/rox/pkg/timestamp"

	"github.com/stackrox/rox/pkg/features"
	"github.com/stackrox/rox/pkg/postgres/pgtest"
	pkgSchema "github.com/stackrox/rox/pkg/postgres/schema"
	"github.com/stackrox/rox/pkg/rocksdb"
	"github.com/stackrox/rox/pkg/sac"
	"github.com/stackrox/rox/pkg/testutils"
	"github.com/stackrox/rox/pkg/testutils/envisolator"
	"github.com/stackrox/rox/pkg/testutils/rocksdbtest"
	"github.com/stretchr/testify/suite"
	"github.com/tecbot/gorocksdb"
	"gorm.io/gorm"
)

func TestMigration(t *testing.T) {
	suite.Run(t, new(postgresMigrationSuite))
}

type postgresMigrationSuite struct {
	suite.Suite
	envIsolator *envisolator.EnvIsolator
	ctx         context.Context

	// LegacyDB to migrate from
	legacyDB *rocksdb.RocksDB

	// PostgresDB
	pool   *pgxpool.Pool
	gormDB *gorm.DB
}

var _ suite.TearDownTestSuite = (*postgresMigrationSuite)(nil)

func (s *postgresMigrationSuite) SetupTest() {
	s.envIsolator = envisolator.NewEnvIsolator(s.T())
	s.envIsolator.Setenv(features.PostgresDatastore.EnvVar(), "true")
	if !features.PostgresDatastore.Enabled() {
		s.T().Skip("Skip postgres store tests")
		s.T().SkipNow()
	}

	var err error
	s.legacyDB, err = rocksdb.NewTemp(s.T().Name())
	s.NoError(err)

	source := pgtest.GetConnectionString(s.T())
	config, err := pgxpool.ParseConfig(source)
	s.Require().NoError(err)

	s.ctx = sac.WithAllAccess(context.Background())
	s.pool, err = pgxpool.ConnectConfig(s.ctx, config)
	s.Require().NoError(err)
	pgtest.CleanUpDB(s.ctx, s.T(), s.pool)
	s.gormDB = pgtest.OpenGormDBWithDisabledConstraints(s.T(), source)
}

func (s *postgresMigrationSuite) TearDownTest() {
	rocksdbtest.TearDownRocksDB(s.legacyDB)
	_ = s.gormDB.Migrator().DropTable(pkgSchema.CreateTableNetworkFlowsStmt.GormModel)
	pgtest.CleanUpDB(s.ctx, s.T(), s.pool)
	pgtest.CloseGormDB(s.T(), s.gormDB)
	s.pool.Close()
}

func (s *postgresMigrationSuite) populateStore(clusterStore store.ClusterStore, clusterID string) (store.FlowStore, []*storage.NetworkFlow) {
	var flows []*storage.NetworkFlow
	for i := 0; i < 50; i++ {
		flow := &storage.NetworkFlow{}
		flow.LastSeenTimestamp = types.TimestampNow()
		flow.ClusterId = "cluster1"
		s.NoError(testutils.FullInit(flow, testutils.UniqueInitializer(), testutils.JSONFieldsFilter))
		flows = append(flows, flow)
	}
	flowStore := clusterStore.GetFlowStore(clusterID)
	s.NoError(flowStore.UpsertFlows(s.ctx, flows, timestamp.FromProtobuf(flows[len(flows)-1].LastSeenTimestamp)))
	return flowStore, flows
}

func (s *postgresMigrationSuite) verify(flowStore store.FlowStore, flows []*storage.NetworkFlow) {
	fetched, _, err := flowStore.GetAllFlows(s.ctx, &types.Timestamp{})
	s.NoError(err)
	s.Len(fetched, len(flows))
	sort.SliceStable(fetched, func(i, j int) bool {
		return fetched[i].LastSeenTimestamp.Compare(fetched[j].LastSeenTimestamp) < 0
	})
	sort.SliceStable(flows, func(i, j int) bool {
		return flows[i].LastSeenTimestamp.Compare(flows[j].LastSeenTimestamp) < 0
	})
	for i, flow := range flows {
		s.Equal(flow, fetched[i])
	}
}

func (s *postgresMigrationSuite) TestMigration() {
	// Prepare data and write to legacy DB
	legacyStore := legacy.NewClusterStore(s.legacyDB)
	rocksWriteBatch := gorocksdb.NewWriteBatch()
	defer rocksWriteBatch.Destroy()

	cluster1FlowStore, cluster1Flows := s.populateStore(legacyStore, "cluster1")
	cluster2FlowStore, cluster2Flows := s.populateStore(legacyStore, "cluster2")

	s.NoError(move(s.gormDB, s.pool, legacyStore))
	s.verify(cluster1FlowStore, cluster1Flows)
	s.verify(cluster2FlowStore, cluster2Flows)
}
